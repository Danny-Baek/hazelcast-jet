<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Sources and Sinks · Hazelcast Jet</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Hazelcast Jet comes out of the box with many different sources and sinks"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Sources and Sinks · Hazelcast Jet"/><meta property="og:type" content="website"/><meta property="og:url" content="https://jet-start.sh/"/><meta property="og:description" content="Hazelcast Jet comes out of the box with many different sources and sinks"/><meta property="og:image" content="https://jet-start.sh/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://jet-start.sh/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="/img/favicon.png"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="alternate" type="application/atom+xml" href="https://jet-start.sh/blog/atom.xml" title="Hazelcast Jet Blog ATOM Feed"/><link rel="alternate" type="application/rss+xml" href="https://jet-start.sh/blog/feed.xml" title="Hazelcast Jet Blog RSS Feed"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-158279495-1', 'auto');
              ga('send', 'pageview');
            </script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,500"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/js/code-block-buttons.js"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/logo-dark.svg" alt="Hazelcast Jet"/></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/docs" target="_self">Documentation</a></li><li class=""><a href="https://github.com/hazelcast/hazelcast-jet/releases" target="_self">Download</a></li><li class=""><a href="https://github.com/hazelcast/hazelcast-jet" target="_self">View on GitHub</a></li><li class=""><a href="/blog/" target="_self">Blog</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Programming Guide</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Get Started<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/get-started/intro">Introduction</a></li><li class="navListItem"><a class="navItem" href="/docs/get-started/first-job">Your First Jet Program</a></li><li class="navListItem"><a class="navItem" href="/docs/get-started/installation">Set Up a Jet Cluster</a></li><li class="navListItem"><a class="navItem" href="/docs/get-started/submit-job">Submit a Job to the Cluster</a></li><li class="navListItem"><a class="navItem" href="/docs/get-started/scale-job">Scale Your Job</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Programming Guide<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/api/pipeline">Building Pipelines</a></li><li class="navListItem"><a class="navItem" href="/docs/api/stateless-transforms">Stateless Transforms</a></li><li class="navListItem"><a class="navItem" href="/docs/api/stateful-transforms">Stateful Transforms</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/docs/api/sources-sinks">Sources and Sinks</a></li><li class="navListItem"><a class="navItem" href="/docs/api/data-structures">Distributed Data Structures</a></li><li class="navListItem"><a class="navItem" href="/docs/api/serialization">Serialization</a></li><li class="navListItem"><a class="navItem" href="/docs/api/testing">Testing</a></li><li class="navListItem"><a class="navItem" href="/docs/api/javadoc">Javadoc</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Tutorials<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/tutorials/map-join">Join Static Data to a Stream</a></li><li class="navListItem"><a class="navItem" href="/docs/tutorials/kafka">Work with Apache Kafka</a></li><li class="navListItem"><a class="navItem" href="/docs/tutorials/observables">Reactive Streams</a></li><li class="navListItem"><a class="navItem" href="/docs/tutorials/cdc">Change Data Capture</a></li><li class="navListItem"><a class="navItem" href="/docs/tutorials/stream-imap">Stream changes from IMap</a></li><li class="navListItem"><a class="navItem" href="/docs/tutorials/python">Apply Transforms using Python</a></li><li class="navListItem"><a class="navItem" href="/docs/tutorials/windowing">Windowed Aggregation</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Concepts<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/concepts/dag">Directed Acylic Graph (DAG)</a></li><li class="navListItem"><a class="navItem" href="/docs/concepts/event-time">Streaming and Event Time</a></li><li class="navListItem"><a class="navItem" href="/docs/concepts/processing-guarantees">Processing Guarantees for Stateful Computation</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Operations Guide<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/operations/configuration">Configuration</a></li><li class="navListItem"><a class="navItem" href="/docs/operations/cluster-sizing">Cluster Sizing</a></li><li class="navListItem"><a class="navItem" href="/docs/operations/job-management">Job Management</a></li><li class="navListItem"><a class="navItem" href="/docs/operations/kubernetes">Jet on Kubernetes</a></li><li class="navListItem"><a class="navItem" href="/docs/operations/monitoring">Monitoring and Metrics</a></li><li class="navListItem"><a class="navItem" href="/docs/operations/spring">Spring Integration</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Architecture<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/architecture/cluster-topology">Cluster Topology</a></li><li class="navListItem"><a class="navItem" href="/docs/architecture/distributed-computing">Distributed Execution</a></li><li class="navListItem"><a class="navItem" href="/docs/architecture/execution-engine">Cooperative Threading</a></li><li class="navListItem"><a class="navItem" href="/docs/architecture/fault-tolerance">Fault Tolerance</a></li><li class="navListItem"><a class="navItem" href="/docs/architecture/in-memory-storage">In-Memory Storage</a></li><li class="navListItem"><a class="navItem" href="/docs/architecture/event-time">Event Time Processing</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Design Documents<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/design-docs/unit-testing">Pipeline API: Unit Testing Support</a></li><li class="navListItem"><a class="navItem" href="/docs/design-docs/kafka-connect">Kafka Connect Source</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Roadmap<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/roadmap">Roadmap</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer docsContainer"><div class="wrapper"><div class="post"><header class="postHeader"><a class="edit-page-link button" href="https://github.com/hazelcast/hazelcast-jet/edit/docs/site/docs/api/sources-sinks.md" target="_blank" rel="noreferrer noopener">Edit</a><h1 id="__docusaurus" class="postHeaderTitle">Sources and Sinks</h1></header><article><div><span><p>Hazelcast Jet comes out of the box with many different sources and sinks
that you can work with, that are also referred to as <em>connectors</em>.</p>
<h2><a class="anchor" aria-hidden="true" id="files"></a><a href="#files" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Files</h2>
<p>File sources generally involve reading a set of (as in &quot;multiple&quot;) files
from either a local/network disk or a distributed file system such as
Amazon S3 or Hadoop. Most file sources and sinks are batch oriented, but
the sinks that support <em>rolling</em> capability can also be used as sinks in
streaming jobs.</p>
<h3><a class="anchor" aria-hidden="true" id="local-disk"></a><a href="#local-disk" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Local Disk</h3>
<p>The simplest file source is designed to work with both local and network
file systems. This source is text-oriented and reads the files line by
line and emits a record per line.</p>
<pre><code class="hljs css language-java">Pipeline p = Pipeline.create();
p.readFrom(Sources.files(<span class="hljs-string">"/home/data/web-logs"</span>))
 .map(line -&gt; LogParser.parse(line))
 .filter(log -&gt; log.level().equals(<span class="hljs-string">"ERROR"</span>))
 .writeTo(Sinks.logger());
</code></pre>
<p>For CSV or JSON files it's possible to use the <code>filesBuilder</code> source:</p>
<pre><code class="hljs css language-java">Pipeline p = Pipeline.create();
p.readFrom(Sources.filesBuilder(sourceDir).glob(<span class="hljs-string">"*.csv"</span>).build(path -&gt;
    Files.lines(path).skip(<span class="hljs-number">1</span>).map(SalesRecordLine::parse))
).writeTo(Sinks.logger());
</code></pre>
<p>For a local file system, the sources expect to see on each node just the
files that node should read. You can achieve the effect of a distributed
source if you manually prepare a different set of files on each node.
For shared file system, the sources can split the work so that each node
will read a part of the files.</p>
<h4><a class="anchor" aria-hidden="true" id="file-sink"></a><a href="#file-sink" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>File Sink</h4>
<p>The file sink, like the source works with text and creates a line of
output for each record. When the rolling option is used it will roll the
filename to a new one once the criteria is met. It supports rolling by
size or date. The following will roll to a new file every hour:</p>
<pre><code class="hljs css language-java">Pipeline p = Pipeline.create();
p.readFrom(TestSources.itemStream(<span class="hljs-number">100</span>))
 .withoutTimestamps()
 .writeTo(Sinks.filesBuilder(<span class="hljs-string">"out"</span>)
 .rollByDate(<span class="hljs-string">"YYYY-MM-dd.HH"</span>)
 .build());
</code></pre>
<p>Each node will write to a unique file with a numerical index. You can
achieve the effect of a distributed sink if you manually collect all the
output files on all members and combine their contents.</p>
<p>The sink also supports exactly-once processing and can work
transactionally.</p>
<h4><a class="anchor" aria-hidden="true" id="file-watcher"></a><a href="#file-watcher" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>File Watcher</h4>
<p>File watcher is a streaming file source, where only the new files,
appended or changed lines are emitted. It expects that files are updated
in append-only fashion.</p>
<pre><code class="hljs css language-java">Pipeline p = Pipeline.create();
p.readFrom(Sources.fileWatcher(<span class="hljs-string">"/home/data"</span>))
 .withoutTimestamps()
 .writeTo(Sinks.logger());
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="apache-avro"></a><a href="#apache-avro" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Apache Avro</h3>
<p><a href="https://avro.apache.org/">Apache Avro</a> is a binary data storage format
which is schema based. The connectors are similar to the local file
connectors, but work with binary files stored in <em>Avro Object Container
File</em> format.</p>
<p>To use the Avro connector, you need to copy the <code>hazelcast-jet-avro</code>
module from the <code>opt</code> folder to the <code>lib</code> folder and add the following
dependency to your application:</p>
<div class="tabs"><div class="nav-tabs"><div id="tab-group-1-tab-2" class="nav-link active" data-group="group_1" data-tab="tab-group-1-content-2">Maven</div><div id="tab-group-1-tab-3" class="nav-link" data-group="group_1" data-tab="tab-group-1-content-3">Gradle</div></div><div class="tab-content"><div id="tab-group-1-content-2" class="tab-pane active" data-group="group_1" tabindex="-1"><div><span><pre><code class="hljs css language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependencies</span>&gt;</span><br />  <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br />    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.hazelcast.jet<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br />    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hazelcast-jet-avro<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br />    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$jet.version<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br />  <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br /><span class="hljs-tag">&lt;/<span class="hljs-name">dependencies</span>&gt;</span><br /></code></pre>
</span></div></div><div id="tab-group-1-content-3" class="tab-pane" data-group="group_1" tabindex="-1"><div><span><pre><code class="hljs css language-groovy">compile <span class="hljs-string">'com.hazelcast.jet:hazelcast-jet-avro:$jet.version'</span><br /></code></pre>
</span></div></div></div></div>
<p>With Avro sources, you can use either the <code>SpecificReader</code> or
<code>DatumReader</code> depending on the data type:</p>
<pre><code class="hljs css language-java">Pipeline p = Pipeline.create();
p.readFrom(AvroSources.files(<span class="hljs-string">"/home/data"</span>, Person<span class="hljs-class">.<span class="hljs-keyword">class</span>))
 .<span class="hljs-title">filter</span>(<span class="hljs-title">person</span> -&gt; <span class="hljs-title">person</span>.<span class="hljs-title">age</span>() &gt; 30)
 .<span class="hljs-title">writeTo</span>(<span class="hljs-title">Sinks</span>.<span class="hljs-title">logger</span>())</span>;
</code></pre>
<p>The sink expects a schema and the type to be written:</p>
<pre><code class="hljs css language-java">p.writeTo(AvroSinks.files(DIRECTORY_NAME, Person.getClassSchema()), Person<span class="hljs-class">.<span class="hljs-keyword">class</span>))
</span></code></pre>
<h3><a class="anchor" aria-hidden="true" id="hadoop-inputformatoutputformat"></a><a href="#hadoop-inputformatoutputformat" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Hadoop InputFormat/OutputFormat</h3>
<p>You can use Hadoop connector to read/write files from/to Hadoop
Distributed File System (HDFS), local file system, or any other system
which has Hadoop connectors, including various cloud storages. Jet was
tested with:</p>
<ul>
<li>Amazon S3</li>
<li>Google Cloud Storage</li>
<li>Azure Cloud Storage</li>
<li>Azure Data Lake</li>
</ul>
<p>The Hadoop source and sink require a configuration object of type
<a href="https://hadoop.apache.org/docs/r2.10.0/api/org/apache/hadoop/conf/Configuration.html">Configuration</a>
which supplies the input and output paths and formats. They don’t
actually create a MapReduce job, this config is simply used to describe
the required inputs and outputs. You can share the same <code>Configuration</code>
instance between several source/sink instances.</p>
<p>For example, to do a canonical word count on a Hadoop data source,
we can use the following pipeline:</p>
<pre><code class="hljs css language-java">Job job = Job.getInstance();
job.setInputFormatClass(TextInputFormat<span class="hljs-class">.<span class="hljs-keyword">class</span>)</span>;
job.setOutputFormatClass(TextOutputFormat<span class="hljs-class">.<span class="hljs-keyword">class</span>)</span>;
TextInputFormat.addInputPath(job, <span class="hljs-keyword">new</span> Path(<span class="hljs-string">"input-path"</span>));
TextOutputFormat.setOutputPath(job, <span class="hljs-keyword">new</span> Path(<span class="hljs-string">"output-path"</span>));
Configuration configuration = job.getConfiguration();

Pipeline p = Pipeline.create();
p.readFrom(HadoopSources.inputFormat(configuration, (k, v) -&gt; v.toString()))
 .flatMap(line -&gt; traverseArray(line.toLowerCase().split(<span class="hljs-string">"\\W+"</span>)))
 .groupingKey(word -&gt; word)
 .aggregate(AggregateOperations.counting())
 .writeTo(HadoopSinks.outputFormat(configuration));
</code></pre>
<p>The Hadoop source and sink will use either the new or the old MapReduce
API based on the input format configuration.</p>
<p>Each processor will write to a different file in the output folder
identified by the unique processor id. The files will be in a temporary
state until the job is completed and will be committed when the job is
complete. For streaming jobs, they will be committed when the job is
cancelled. We have plans to introduce a rolling sink for Hadoop in the
future to have better streaming support.</p>
<h4><a class="anchor" aria-hidden="true" id="data-locality"></a><a href="#data-locality" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Data Locality</h4>
<p>Jet will split the input data across the cluster, with each processor
instance reading a part of the input. If the Jet nodes are co-located
with the Hadoop data nodes, then Jet can make use of data locality by
reading the blocks locally where possible. This can bring a significant
increase in read throughput.</p>
<h4><a class="anchor" aria-hidden="true" id="serialization-and-writables"></a><a href="#serialization-and-writables" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Serialization and Writables</h4>
<p>Hadoop types implement their own serialization mechanism through the use
of <code>Writable</code> types. Jet provides an adapter to register a <code>Writable</code>
for <a href="serialization">Hazelcast serialization</a> without having to write
additional serialization code. To use this adapter, you can register
your own <code>Writable</code> types by extending <code>WritableSerializerHook</code> and
registering the hook.</p>
<h4><a class="anchor" aria-hidden="true" id="hadoop-classpath"></a><a href="#hadoop-classpath" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Hadoop Classpath</h4>
<p>To use the Hadoop connector, you need to copy the <code>hazelcast-jet-hadoop</code>
module from the <code>opt</code> folder to the <code>lib</code> folder and add the following
dependency to your application:</p>
<div class="tabs"><div class="nav-tabs"><div id="tab-group-4-tab-5" class="nav-link active" data-group="group_4" data-tab="tab-group-4-content-5">Maven</div><div id="tab-group-4-tab-6" class="nav-link" data-group="group_4" data-tab="tab-group-4-content-6">Gradle</div></div><div class="tab-content"><div id="tab-group-4-content-5" class="tab-pane active" data-group="group_4" tabindex="-1"><div><span><pre><code class="hljs css language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependencies</span>&gt;</span><br />  <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br />    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.hazelcast.jet<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br />    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hazelcast-jet-hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br />    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$jet.version<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br />  <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br /><span class="hljs-tag">&lt;/<span class="hljs-name">dependencies</span>&gt;</span><br /></code></pre>
</span></div></div><div id="tab-group-4-content-6" class="tab-pane" data-group="group_4" tabindex="-1"><div><span><pre><code class="hljs css language-groovy">compile <span class="hljs-string">'com.hazelcast.jet:hazelcast-jet-hadoop:$jet.version'</span><br /></code></pre>
</span></div></div></div></div>
<p>When submitting Jet jobs using Hadoop, sending Hadoop JARs should be
avoided and instead the Hadoop classpath should be used. Hadoop JARs
contain some JVM hooks and can keep lingering references inside the JVM
long after the job has ended, causing memory leaks.</p>
<p>To obtain the hadoop classpath, use the <code>hadoop classpath</code> command and
append the output to the <code>CLASSPATH</code> environment variable before
starting Jet.</p>
<h3><a class="anchor" aria-hidden="true" id="amazon-s3"></a><a href="#amazon-s3" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Amazon S3</h3>
<p>The Amazon S3 connectors are text-based connectors that can read and
write files to Amazon S3 storage.</p>
<p>The connectors expect the user to provide either an <code>S3Client</code> instance
or credentials (or using the default ones) to create the client. The
source and sink assume the data is in the form of plain text and
emit/receive data items which represent individual lines of text.</p>
<pre><code class="hljs css language-java">AwsBasicCredentials credentials = AwsBasicCredentials.create(<span class="hljs-string">"accessKeyId"</span>, <span class="hljs-string">"accessKeySecret"</span>);
S3Client s3 = S3Client.builder()
    .credentialsProvider(StaticCredentialsProvider.create(credentials))
    .build();

Pipeline p = Pipeline.create();
p.readFrom(S3Sources.s3(singletonList(<span class="hljs-string">"input-bucket"</span>), <span class="hljs-string">"prefix"</span>,
    () -&gt; S3Client.builder().credentialsProvider(StaticCredentialsProvider.create(credentials)).build())
 .filter(line -&gt; line.contains(<span class="hljs-string">"ERROR"</span>))
 .writeTo(Sinks.logger());
</code></pre>
<p>The S3 sink works similar to the local file sink, writing a line to the
output for each input item:</p>
<pre><code class="hljs css language-java">Pipeline p = Pipeline.create();
p.readFrom(TestSources.items(<span class="hljs-string">"the"</span>, <span class="hljs-string">"brown"</span>, <span class="hljs-string">"fox"</span>))
 .writeTo(S3Sinks.s3(<span class="hljs-string">"output-bucket"</span>, () -&gt; S3Client.create()));
</code></pre>
<p>The sink creates an object in the bucket for each processor instance.
Name of the file will include a user provided prefix (if defined),
followed by the processor’s global index. For example the processor
having the index <code>2</code> with prefix <code>my-object-</code> will create the object
<code>my-object-2</code>.</p>
<p>S3 sink uses the multi-part upload feature of S3 SDK. The sink buffers
the items to parts and uploads them after buffer reaches to the
threshold. The multi-part upload is completed when the job completes and
makes the objects available on the S3. Since a streaming jobs never
complete, S3 sink is not currently applicable to streaming jobs.</p>
<p>To use the S3 connector, you need to add the <code>hazelcast-jet-s3</code>
module to the <code>lib</code> folder and the following dependency to your
application:</p>
<div class="tabs"><div class="nav-tabs"><div id="tab-group-7-tab-8" class="nav-link active" data-group="group_7" data-tab="tab-group-7-content-8">Maven</div><div id="tab-group-7-tab-9" class="nav-link" data-group="group_7" data-tab="tab-group-7-content-9">Gradle</div></div><div class="tab-content"><div id="tab-group-7-content-8" class="tab-pane active" data-group="group_7" tabindex="-1"><div><span><pre><code class="hljs css language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependencies</span>&gt;</span><br />  <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br />    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.hazelcast.jet<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br />    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hazelcast-jet-s3<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br />    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$jet.version<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br />  <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br /><span class="hljs-tag">&lt;/<span class="hljs-name">dependencies</span>&gt;</span><br /></code></pre>
</span></div></div><div id="tab-group-7-content-9" class="tab-pane" data-group="group_7" tabindex="-1"><div><span><pre><code class="hljs css language-groovy">compile <span class="hljs-string">'com.hazelcast.jet:hazelcast-jet-s3:$jet.version'</span><br /></code></pre>
</span></div></div></div></div>
<h2><a class="anchor" aria-hidden="true" id="messaging-systems"></a><a href="#messaging-systems" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Messaging Systems</h2>
<p>Messaging systems allow multiple application to communicate
asynchronously without a direct link between them. These types of
systems are a great fit for a stream processing engine like Jet since
Jet is able to consume messages from these systems and process them in
real time.</p>
<h3><a class="anchor" aria-hidden="true" id="apache-kafka"></a><a href="#apache-kafka" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Apache Kafka</h3>
<p>Apache Kafka is a popular distributed, persistent log store which is a
great fit for stream processing systems. Data in Kafka is structured
as <em>topics</em> and each topic consists of one or more partitions, stored in
the Kafka cluster.</p>
<p>To read from Kafka, the only requirements are to provide deserializers
and a topic name:</p>
<pre><code class="hljs css language-java">Properties props = <span class="hljs-keyword">new</span> Properties();
props.setProperty(<span class="hljs-string">"bootstrap.servers"</span>, <span class="hljs-string">"localhost:9092"</span>);
props.setProperty(<span class="hljs-string">"key.deserializer"</span>, StringDeserializer<span class="hljs-class">.<span class="hljs-keyword">class</span>.<span class="hljs-title">getCanonicalName</span>())</span>;
props.setProperty(<span class="hljs-string">"value.deserializer"</span>, StringDeserializer<span class="hljs-class">.<span class="hljs-keyword">class</span>.<span class="hljs-title">getCanonicalName</span>())</span>;
props.setProperty(<span class="hljs-string">"auto.offset.reset"</span>, <span class="hljs-string">"earliest"</span>);

Pipeline p = Pipeline.create();
p.readFrom(KafkaSources.kafka(props, <span class="hljs-string">"topic"</span>))
 .withNativeTimestamps(<span class="hljs-number">0</span>)
 .writeTo(Sinks.logger());
</code></pre>
<p>The topics and partitions are distributed across the Jet cluster, so
that each node is responsible for reading a subset of the data.</p>
<p>When used as a sink, then the only requirements are the serializers:</p>
<pre><code class="hljs css language-java">Properties props = <span class="hljs-keyword">new</span> Properties();
props.setProperty(<span class="hljs-string">"bootstrap.servers"</span>, <span class="hljs-string">"localhost:9092"</span>);
props.setProperty(<span class="hljs-string">"key.serializer"</span>, StringSerializer<span class="hljs-class">.<span class="hljs-keyword">class</span>.<span class="hljs-title">getCanonicalName</span>())</span>;
props.setProperty(<span class="hljs-string">"value.serializer"</span>, StringSerializer<span class="hljs-class">.<span class="hljs-keyword">class</span>.<span class="hljs-title">getCanonicalName</span>())</span>;

Pipeline p = Pipeline.create();
p.readFrom(Sources.files(<span class="hljs-string">"home/logs"</span>))
 .map(line -&gt; LogParser.parse(line))
 .map(log -&gt; entry(log.service(), log.message()))
 .writeTo(KafkaSinks.kafka(props, <span class="hljs-string">"topic"</span>));
</code></pre>
<p>To use the Kafka connector, you need to copy the <code>hazelcast-jet-kafka</code>
module from the <code>opt</code> folder to the <code>lib</code> folder and add the following
dependency to your application:</p>
<div class="tabs"><div class="nav-tabs"><div id="tab-group-10-tab-11" class="nav-link active" data-group="group_10" data-tab="tab-group-10-content-11">Maven</div><div id="tab-group-10-tab-12" class="nav-link" data-group="group_10" data-tab="tab-group-10-content-12">Gradle</div></div><div class="tab-content"><div id="tab-group-10-content-11" class="tab-pane active" data-group="group_10" tabindex="-1"><div><span><pre><code class="hljs css language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependencies</span>&gt;</span><br />  <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br />    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.hazelcast.jet<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br />    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hazelcast-jet-kafka<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br />    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$jet.version<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br />  <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br /><span class="hljs-tag">&lt;/<span class="hljs-name">dependencies</span>&gt;</span><br /></code></pre>
</span></div></div><div id="tab-group-10-content-12" class="tab-pane" data-group="group_10" tabindex="-1"><div><span><pre><code class="hljs css language-groovy"><br />compile <span class="hljs-string">'com.hazelcast.jet:hazelcast-jet-kafka:$jet.version'</span><br /></code></pre>
</span></div></div></div></div>
<h4><a class="anchor" aria-hidden="true" id="fault-tolerance"></a><a href="#fault-tolerance" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fault-tolerance</h4>
<p>One of the most important features of using Kafka as a source is that
it's possible to replay data - which enables fault-tolerance. If the job
has a processing guarantee configured, then Jet will periodically save
the current offsets internally and then replay from the saved offset
when the job is restarted. In this mode, Jet will manually track and
commit offsets, without interacting with the consumer groups feature of
Kafka.</p>
<p>If processing guarantee is disabled, the source will start reading from
default offsets (based on the <code>auto.offset.reset property</code>). You can
enable offset committing by assigning a <code>group.id</code>, enabling auto offset
committing using <code>enable.auto.commit</code> and configuring
<code>auto.commit.interval.ms</code> in the given properties. Refer to
<a href="https://kafka.apache.org/22/documentation.html">Kafka documentation</a>
for the descriptions of these properties.</p>
<h4><a class="anchor" aria-hidden="true" id="transactional-guarantees"></a><a href="#transactional-guarantees" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Transactional guarantees</h4>
<p>As a sink, it provides exactly-once guarantees at the cost of using
Kafka transactions: Jet commits the produced records after each snapshot
is completed. This greatly increases the latency because consumers see
the records only after they are committed.</p>
<p>If you use at-least-once guarantee, records are visible immediately, but
in the case of a failure some records could be duplicated. You
can also have the job in exactly-once mode and decrease the guarantee
just for a particular Kafka sink.</p>
<h4><a class="anchor" aria-hidden="true" id="version-compatibility"></a><a href="#version-compatibility" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Version Compatibility</h4>
<p>The Kafka sink and source are based on version 2.2.0, this means Kafka
connector will work with any client and broker having version equal to
or greater than 1.0.0.</p>
<h3><a class="anchor" aria-hidden="true" id="jms"></a><a href="#jms" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>JMS</h3>
<p>JMS (Java Message Service) is a standard API for communicating with
various message brokers using the publish-subscribe patterns.</p>
<p>There are several brokers that implement the JMS standard, including:</p>
<ul>
<li>Apache ActiveMQ and ActiveMQ Artemis</li>
<li>Amazon SQS</li>
<li>IBM MQ</li>
<li>RabbitMQ</li>
<li>Solace</li>
</ul>
<p>Jet is able to utilize these brokers both as a source and sink through
the use of the JMS API.</p>
<p>To use a JMS broker, such as ActiveMQ, you'll need the client libraries
either on the classpath (by putting them on the <code>lib</code> folder) of the
node or submit them with the job. The Jet JMS connector is part of the
<code>hazelcast-jet</code> module, so requires no other dependencies than the
client jar.</p>
<p>A very simple pipeline which consumes messages from a given ActiveMQ
and then logs them is given below:</p>
<pre><code class="hljs css language-java">Pipeline p = Pipeline.create();
p.readFrom(Sources.jmsQueue(() -&gt; <span class="hljs-keyword">new</span> ActiveMQConnectionFactory(
        <span class="hljs-string">"tcp://localhost:61616"</span>), <span class="hljs-string">"queue"</span>))
 .withoutTimestamps()
 .writeTo(Sinks.logger());
</code></pre>
<p>For the topic, we recommend using a durable consumer where possible
so that you are able to make use of fault-tolerance features of Jet:</p>
<pre><code class="hljs css language-java">Pipeline p = Pipeline.create();
p.readFrom(Sources.jmsTopicBuilder(() -&gt;
    <span class="hljs-keyword">new</span> ActiveMQConnectionFactory(<span class="hljs-string">"tcp://localhost:61616"</span>)
        .sharedConsumer(<span class="hljs-keyword">true</span>)
        .consumerFn(session -&gt; {
            Topic topic = session.createTopic(<span class="hljs-string">"topic"</span>);
            <span class="hljs-keyword">return</span> session.createSharedDurableConsumer(topic, <span class="hljs-string">"consumer-name"</span>);
        })
        .build())
 .withoutTimestamps()
 .writeTo(Sinks.logger());
</code></pre>
<p>The JMS topic, if not consumed by a shared consumer, is a
non-distributed source. If messages are consumed by multiple consumers,
all of them will get the same messages. Therefore the source operates
on a single member with local parallelism of 1. If you create a shared
consumer in the <code>consumerFn</code>, you should call <code>sharedConsumer(true)</code> on
the builder, as in the sample code above. For a queue we always assume
a shared consumer.</p>
<h4><a class="anchor" aria-hidden="true" id="using-as-a-sink"></a><a href="#using-as-a-sink" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Using as a sink</h4>
<p>The JMS sink uses the supplied function to create a Message object for
each input item. After a batch of messages is sent, sink commits the
session.</p>
<p>The following code snippets show writing to a JMS queue and a JMS topic
using ActiveMQ JMS Client.</p>
<pre><code class="hljs css language-java">Pipeline p = Pipeline.create();
p.readFrom(Sources.list(<span class="hljs-string">"inputList"</span>))
 .writeTo(Sinks.jmsQueue(<span class="hljs-string">"queue"</span>,
         () -&gt; <span class="hljs-keyword">new</span> ActiveMQConnectionFactory(<span class="hljs-string">"tcp://localhost:61616"</span>)));
</code></pre>
<pre><code class="hljs css language-java">Pipeline p = Pipeline.create();
p.readFrom(Sources.list(<span class="hljs-string">"inputList"</span>))
 .writeTo(Sinks.jmsTopic(<span class="hljs-string">"topic"</span>,
        () -&gt; <span class="hljs-keyword">new</span> ActiveMQConnectionFactory(<span class="hljs-string">"tcp://localhost:61616"</span>)));
</code></pre>
<h4><a class="anchor" aria-hidden="true" id="connection-handling"></a><a href="#connection-handling" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Connection Handling</h4>
<p>The JMS connectors opens one connection to the JMS server for each
member. Then each underlying worker of the source creates a session and
a message consumer using that connection. The user supplies necessary
functions to create the connection, session and message consumer.</p>
<p>IO failures are generally handled by the JMS Client and do not cause the
connector to fail. Most of the clients offer a configuration parameter
to enable auto-reconnection, refer to the specific client documentation
for details.</p>
<h4><a class="anchor" aria-hidden="true" id="fault-tolerance-1"></a><a href="#fault-tolerance-1" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fault Tolerance</h4>
<p>JMS for Jet is a transactional source, and supports both at-least-once
and exactly-once processing. The sink currently supports at-least-once
and will be extended to have exactly-once guarantee through the use XA
transactions in the future.</p>
<p>If you have no processing guarantee enabled, the processor will consume
the messages in <code>DUPS_OK_ACKNOWLEDGE</code> mode, and otherwise will only
acknowledge messages in transactions in the 2nd phase of the snapshot,
that is after all downstream stages (including any sinks) fully
processed the messages. Additionally, if the exactly-pnce processing
guarantee is used, the processor will store message IDs of the
unacknowledged messages to the snapshot and should the job fail after
the snapshot was successful, but before Jet managed to acknowledge the
messages, the stored IDs will be used to filter out the re-delivered
messages to avoid duplication.</p>
<p>The exactly-once guarantee for JMS topic requires the use of a durable
topic consumer, since the broker doesn't store and can't replay messages
otherwise.</p>
<h3><a class="anchor" aria-hidden="true" id="apache-pulsar"></a><a href="#apache-pulsar" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Apache Pulsar</h3>
<blockquote>
<p>This connector is under incubation.</p>
</blockquote>
<h2><a class="anchor" aria-hidden="true" id="in-memory-data-structures"></a><a href="#in-memory-data-structures" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>In-memory data structures</h2>
<h3><a class="anchor" aria-hidden="true" id="imap"></a><a href="#imap" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>IMap</h3>
<h3><a class="anchor" aria-hidden="true" id="ilist"></a><a href="#ilist" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>IList</h3>
<h3><a class="anchor" aria-hidden="true" id="icache"></a><a href="#icache" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>ICache</h3>
<h3><a class="anchor" aria-hidden="true" id="reliable-topic"></a><a href="#reliable-topic" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Reliable Topic</h3>
<h2><a class="anchor" aria-hidden="true" id="databases"></a><a href="#databases" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Databases</h2>
<h3><a class="anchor" aria-hidden="true" id="jdbc"></a><a href="#jdbc" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>JDBC</h3>
<h3><a class="anchor" aria-hidden="true" id="mongodb"></a><a href="#mongodb" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>MongoDB</h3>
<blockquote>
<p>This connector is currently under incubation. For more
information and examples, please visit the <a href="https://github.com/hazelcast/hazelcast-jet-contrib/tree/master/mongodb">GitHub repository</a>.</p>
</blockquote>
<h3><a class="anchor" aria-hidden="true" id="influxdb"></a><a href="#influxdb" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>InfluxDB</h3>
<blockquote>
<p>This connector is currently under incubation. For more
information and examples, please visit the <a href="https://github.com/hazelcast/hazelcast-jet-contrib/tree/master/influxdb">GitHub repository</a>.</p>
</blockquote>
<h3><a class="anchor" aria-hidden="true" id="elasticsearch"></a><a href="#elasticsearch" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Elasticsearch</h3>
<blockquote>
<p>This connector is currently under incubation. For more
information and examples, please visit the <a href="https://github.com/hazelcast/hazelcast-jet-contrib/tree/master/elasticsearch">GitHub repository</a>.</p>
</blockquote>
<h3><a class="anchor" aria-hidden="true" id="debezium"></a><a href="#debezium" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Debezium</h3>
<blockquote>
<p>This connector is currently under incubation. For more
information and examples, please visit the <a href="https://github.com/hazelcast/hazelcast-jet-contrib/tree/master/debezium">GitHub repository</a>.</p>
</blockquote>
<h3><a class="anchor" aria-hidden="true" id="redis"></a><a href="#redis" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Redis</h3>
<blockquote>
<p>This connector is currently under incubation. For more
information and examples, please visit the <a href="https://github.com/hazelcast/hazelcast-jet-contrib/tree/master/redis">GitHub repository</a>.</p>
</blockquote>
<h2><a class="anchor" aria-hidden="true" id="miscellaneous"></a><a href="#miscellaneous" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Miscellaneous</h2>
<h3><a class="anchor" aria-hidden="true" id="test-sources"></a><a href="#test-sources" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Test Sources</h3>
<h3><a class="anchor" aria-hidden="true" id="socket"></a><a href="#socket" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Socket</h3>
<h3><a class="anchor" aria-hidden="true" id="twitter"></a><a href="#twitter" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Twitter</h3>
<blockquote>
<p>This connector is currently under incubation. For more
information and examples, please visit the <a href="https://github.com/hazelcast/hazelcast-jet-contrib/tree/master/twitter">GitHub repository</a>.</p>
</blockquote>
<h2><a class="anchor" aria-hidden="true" id="summary"></a><a href="#summary" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Summary</h2>
<h3><a class="anchor" aria-hidden="true" id="sources"></a><a href="#sources" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Sources</h3>
<table>
<thead>
<tr><th style="text-align:left">source</th><th style="text-align:left">module</th><th style="text-align:left">batch/stream</th><th style="text-align:left">guarantee</th></tr>
</thead>
<tbody>
<tr><td style="text-align:left"><code>AvroSources.files</code></td><td style="text-align:left"><code>hazelcast-jet-avro</code></td><td style="text-align:left">batch</td><td style="text-align:left">N/A</td></tr>
<tr><td style="text-align:left"><code>HadoopSources.inputFormat</code></td><td style="text-align:left"><code>hazelcast-jet-hadoop</code></td><td style="text-align:left">batch</td><td style="text-align:left">N/A</td></tr>
<tr><td style="text-align:left"><code>KafkaSources.kafka</code></td><td style="text-align:left"><code>hazelcast-jet-kafka</code></td><td style="text-align:left">stream</td><td style="text-align:left">exactly-once</td></tr>
<tr><td style="text-align:left"><code>S3Sources.s3</code></td><td style="text-align:left"><code>hazelcast-jet-s3</code></td><td style="text-align:left">batch</td><td style="text-align:left">N/A</td></tr>
<tr><td style="text-align:left"><code>Sources.files</code></td><td style="text-align:left"><code>hazelcast-jet</code></td><td style="text-align:left">batch</td><td style="text-align:left">N/A</td></tr>
<tr><td style="text-align:left"><code>Sources.fileWatcher</code></td><td style="text-align:left"><code>hazelcast-jet</code></td><td style="text-align:left">stream</td><td style="text-align:left">N/A</td></tr>
<tr><td style="text-align:left"><code>Sources.jmsQueue</code></td><td style="text-align:left"><code>hazelcast-jet</code></td><td style="text-align:left">stream</td><td style="text-align:left">exactly-once</td></tr>
</tbody>
</table>
<h3><a class="anchor" aria-hidden="true" id="sinks"></a><a href="#sinks" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Sinks</h3>
<table>
<thead>
<tr><th style="text-align:left">sink</th><th style="text-align:left">module</th><th style="text-align:left">streaming support</th><th style="text-align:left">guarantee</th></tr>
</thead>
<tbody>
<tr><td style="text-align:left"><code>AvroSinks.files</code></td><td style="text-align:left"><code>hazelcast-jet-avro</code></td><td style="text-align:left">no</td><td style="text-align:left">N/A</td></tr>
<tr><td style="text-align:left"><code>HadoopSinks.outputFormat</code></td><td style="text-align:left"><code>hazelcast-jet-hadoop</code></td><td style="text-align:left">no</td><td style="text-align:left">N/A</td></tr>
<tr><td style="text-align:left"><code>KafkaSinks.kafka</code></td><td style="text-align:left"><code>hazelcast-jet-kafka</code></td><td style="text-align:left">yes</td><td style="text-align:left">exactly-once</td></tr>
<tr><td style="text-align:left"><code>S3Sinks.s3</code></td><td style="text-align:left"><code>hazelcast-jet-s3</code></td><td style="text-align:left">no</td><td style="text-align:left">N/A</td></tr>
<tr><td style="text-align:left"><code>Sinks.files</code></td><td style="text-align:left"><code>hazelcast-jet</code></td><td style="text-align:left">yes</td><td style="text-align:left">exactly-once</td></tr>
<tr><td style="text-align:left"><code>Sinks.jmsQueue</code></td><td style="text-align:left"><code>hazelcast-jet</code></td><td style="text-align:left">yes</td><td style="text-align:left">at-least-once</td></tr>
</tbody>
</table>
<h2><a class="anchor" aria-hidden="true" id="custom-sources-and-sinks"></a><a href="#custom-sources-and-sinks" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Custom Sources and Sinks</h2>
<h3><a class="anchor" aria-hidden="true" id="sourcebuilder"></a><a href="#sourcebuilder" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>SourceBuilder</h3>
<h3><a class="anchor" aria-hidden="true" id="sinkbuilder"></a><a href="#sinkbuilder" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>SinkBuilder</h3>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="/docs/api/stateful-transforms"><span class="arrow-prev">← </span><span>Stateful Transforms</span></a><a class="docs-next button" href="/docs/api/data-structures"><span>Distributed Data Structures</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#files">Files</a><ul class="toc-headings"><li><a href="#local-disk">Local Disk</a></li><li><a href="#apache-avro">Apache Avro</a></li><li><a href="#hadoop-inputformatoutputformat">Hadoop InputFormat/OutputFormat</a></li><li><a href="#amazon-s3">Amazon S3</a></li></ul></li><li><a href="#messaging-systems">Messaging Systems</a><ul class="toc-headings"><li><a href="#apache-kafka">Apache Kafka</a></li><li><a href="#jms">JMS</a></li><li><a href="#apache-pulsar">Apache Pulsar</a></li></ul></li><li><a href="#in-memory-data-structures">In-memory data structures</a><ul class="toc-headings"><li><a href="#imap">IMap</a></li><li><a href="#ilist">IList</a></li><li><a href="#icache">ICache</a></li><li><a href="#reliable-topic">Reliable Topic</a></li></ul></li><li><a href="#databases">Databases</a><ul class="toc-headings"><li><a href="#jdbc">JDBC</a></li><li><a href="#mongodb">MongoDB</a></li><li><a href="#influxdb">InfluxDB</a></li><li><a href="#elasticsearch">Elasticsearch</a></li><li><a href="#debezium">Debezium</a></li><li><a href="#redis">Redis</a></li></ul></li><li><a href="#miscellaneous">Miscellaneous</a><ul class="toc-headings"><li><a href="#test-sources">Test Sources</a></li><li><a href="#socket">Socket</a></li><li><a href="#twitter">Twitter</a></li></ul></li><li><a href="#summary">Summary</a><ul class="toc-headings"><li><a href="#sources">Sources</a></li><li><a href="#sinks">Sinks</a></li></ul></li><li><a href="#custom-sources-and-sinks">Custom Sources and Sinks</a><ul class="toc-headings"><li><a href="#sourcebuilder">SourceBuilder</a></li><li><a href="#sinkbuilder">SinkBuilder</a></li></ul></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/" class="nav-home"><img src="/img/logo-light.svg" alt="Hazelcast Jet" width="200" height="40"/></a><div><h5>Docs</h5><a href="/docs/get-started/intro">Get Started</a><a href="/docs/tutorials/kafka">Tutorials</a><a href="/docs/operations/configuration">Operations Guide</a><a href="/docs/concepts/distributed-computing">Concepts and Architecture</a></div><div><h5>Community</h5><a href="https://groups.google.com/forum/#!forum/hazelcast-jet" target="_blank" rel="noreferrer noopener">Google Groups</a><a href="http://stackoverflow.com/questions/tagged/hazelcast-jet" target="_blank" rel="noreferrer noopener">Stack Overflow</a><a href="https://gitter.im/hazelcast/hazelcast-jet">Gitter Chat</a></div><div><h5>Latest From the Blog</h5><a href="/blog/2020/02/20/transactional-processors">Transactional connectors in Hazelcast Jet</a><a href="/blog/2020/01/28/new-website">Announcing New Documentation Website</a><a href="/blog/2019/11/12/stream-deduplication">Stream Deduplication with Hazelcast Jet</a></div><div><h5>More</h5><a href="https://github.com/hazelcast/hazelcast-jet">GitHub Project</a><a href="https://github.com/hazelcast/hazelcast-jet/issues">Issue Tracker</a><a href="http://hazelcast.com/company/careers/">Work at Hazelcast</a><a class="github-button" href="https://github.com/hazelcast/hazelcast-jet" data-icon="octicon-star" data-count-href="/facebook/docusaurus/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star this project on GitHub">Star</a></div></section><section class="copyright">Copyright © 2020 Hazelcast Inc.</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '79d1e4941621b9fd761d279d4d19ed69',
                indexName: 'hazelcast-jet',
                inputSelector: '#search_input_react',
                algoliaOptions: {}
              });
            </script></body></html>