<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Blog · Hazelcast Jet</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Distributed Stream and Batch Processing"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Blog · Hazelcast Jet"/><meta property="og:type" content="website"/><meta property="og:url" content="https://jet-start.sh/"/><meta property="og:description" content="Distributed Stream and Batch Processing"/><meta property="og:image" content="https://jet-start.sh/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://jet-start.sh/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="/img/favicon.png"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="alternate" type="application/atom+xml" href="https://jet-start.sh/blog/atom.xml" title="Hazelcast Jet Blog ATOM Feed"/><link rel="alternate" type="application/rss+xml" href="https://jet-start.sh/blog/feed.xml" title="Hazelcast Jet Blog RSS Feed"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-158279495-1', 'auto');
              ga('send', 'pageview');
            </script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,500"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/js/code-block-buttons.js"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body class="blog"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/logo-dark.svg" alt="Hazelcast Jet"/></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/docs/get-started/intro" target="_self">Documentation</a></li><li class=""><a href="https://github.com/hazelcast/hazelcast-jet/releases" target="_self">Releases</a></li><li class=""><a href="https://github.com/hazelcast/hazelcast-jet" target="_self">View on GitHub</a></li><li class="siteNavGroupActive siteNavItemActive"><a href="/blog/" target="_self">Blog</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Recent Posts</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Recent Posts</h3><ul class=""><li class="navListItem"><a class="navItem" href="/blog/2020/02/20/transactional-processors">Transactional connectors in Hazelcast Jet</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/01/28/new-website">Announcing New Documentation Website</a></li><li class="navListItem"><a class="navItem" href="/blog/2019/11/12/stream-deduplication">Stream Deduplication with Hazelcast Jet</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer postContainer blogContainer"><div class="wrapper"><div class="posts"><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/02/20/transactional-processors">Transactional connectors in Hazelcast Jet</a></h1><p class="post-meta">February 20, 2020</p><div class="authorBlock"><p class="post-authorName"><a target="_blank" rel="noreferrer noopener">Viliam Ďurina</a></p><div class="authorPhoto"><a target="_blank" rel="noreferrer noopener"><img src="https://en.gravatar.com/userimage/154381144/a68feb9e86a976869d646e7cf7669510.jpg" alt="Viliam Ďurina"/></a></div></div></header><article class="post-content"><div><span><p>Hazelcast Jet is a distributed stream processing engine which supports
exactly-once semantics even in the presence of cluster member failures.
This is achieved by snapshotting the internal state of the processors at
regular intervals into a reliable storage and then, in case of a
failure, using the latest snapshot to restore the state and continue.</p>
<p>However, the exactly-once guarantee didn't work with most of the
connectors. Only <a href="https://docs.hazelcast.org/docs/jet/latest-dev/manual/#replayable-source">replayable
sources</a>,
such as Apache Kafka or IMap Journal were supported. And no sink
supported this level of guarantee. Why was that?</p>
<p>The original snapshot API had only one phase. A processor was asked to
save its state at regular intervals and that was it. But a sink writes
items to some external resource and must commit if the snapshot was
successful; and it must not commit if it wasn't. It also needs to ensure
that if some processor committed, all will commit, even in the presence
of failures. This is where distributed transactions come to the rescue.</p>
<h2><a class="anchor" aria-hidden="true" id="distributed-transactions"></a><a href="#distributed-transactions" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Distributed transactions</h2>
<p>Jet uses the two-phase commit algorithm to coordinate individual
transactions. The basic algorithm is simple:</p>
<ol>
<li><p>The coordinator asks all participants to prepare for commit</p></li>
<li><p>If all participants were successful, the coordinator asks them to
commit. Otherwise it asks all of them to roll back</p></li>
</ol>
<p>For correct functionality it is required that if a participant reported
success in the first phase, it must be able to commit when requested.</p>
<p>Jet acts as a transaction coordinator. Individual processors (that is
the parallel workers doing the writes) are adapters to actual
transactional resources, that is to databases, message queues etc. So
even if you have just one transactional connector in your pipeline, you
have multiple participants of a distributed transaction, one on each
cluster member.</p>
<h2><a class="anchor" aria-hidden="true" id="two-phase-snapshot-procedure"></a><a href="#two-phase-snapshot-procedure" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Two-phase snapshot procedure</h2>
<p>The commit procedure in Jet is tied to the life cycle of the snapshot.
When a snapshot is taken, the previous transaction is committed and a
new one is started. The snapshot also serves as the durable storage for
the coordinator.</p>
<p>Since Jet 4.0, the snapshot has two phases. In the first phase the
participants prepare, in the second phase they commit. Important thing
is that the snapshot is successful and can be used to restore the state
of a job after the 1st phase is successful. If the job fails before
executing the 2nd phase, that is without executing the commits, the
processors must be able to commit the transactions after the job
restart. To do so, they store transaction IDs to the snapshot. This is
the basic process:</p>
<ol>
<li><p>When a processor starts, it opens transaction <code>T0</code>. It writes
incoming items, but doesn't commit.</p></li>
<li><p>Later the processor is asked to do the 1st phase of the snapshot (the
<code>snapshotCommitPrepare()</code> method). The processor prepares <code>T0</code>,
stores its ID to the snapshot and starts <code>T1</code>.</p></li>
<li><p>Items that arrive until the 2nd phase occurs are handled using <code>T1</code>.</p></li>
<li><p>When a coordinator member receives responses from all processors that
they successfully did 1st phase, it marks the snapshot as successful
and initiates the phase-2.</p></li>
<li><p>Some time later the processor is asked to do the 2nd phase (the
<code>snapshotCommitFinish()</code> method). The processor now commits <code>T0</code> and
continues to use <code>T1</code> until the next snapshot.</p></li>
<li><p>The process repeats with incremented transaction ID.</p></li>
</ol>
<p>Keep in mind that a failure can occur at or between any of the above
steps and exactly-once guarantee must be preserved. If it occurs before
step 2, the transaction is just rolled back by the remote system when
the client disconnects.</p>
<p>If it occurs between steps 2-4, items in <code>T1</code> are are rolled back by the
remote system because the transaction wasn't prepared (the XA API
requires this). But there's also <code>T0</code> that is prepared, but not
committed. After the job restarts, it will restore from a previous
snapshot (step 4 wasn't yet executed), and since <code>T0</code> isn't found in the
restored state, it will be rolled back.</p>
<p>If the failure occurs after step 4, then after the job restarts, it will
try to commit all transaction IDs found in the restored state. So it
will try to commit <code>T0</code>. The commit must be idempotent: if that
transaction was already committed, it should do nothing, because we
don't know if the step 5 was executed or not.</p>
<h2><a class="anchor" aria-hidden="true" id="consistency-with-internal-state"></a><a href="#consistency-with-internal-state" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Consistency with internal state</h2>
<p>The 1st phase is common for transactional processors and for processors
that only save internal state. It is coordinated using the snapshot
barrier, based on the <a href="https://docs.hazelcast.org/docs/jet/latest-dev/manual/#distributed-snapshot">Chandy-Lamport
algorithm</a>.
The consequence is that the moment at which internal processors save
their state and external processors prepare and switch their
transactions is the same. Therefore you can combine exactly-once stages
of any type in the pipeline and it will work seamlessly.</p>
<h2><a class="anchor" aria-hidden="true" id="transactions-are-needed-for-sources-too"></a><a href="#transactions-are-needed-for-sources-too" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Transactions are needed for sources too</h2>
<p>It might seem that since sources are designed to be read, we don’t need
anything to store. But, for example, some message systems use
acknowledgements, which are in fact writes: they change the state of the
message to consumed or they delete the message.</p>
<p>Jet supports JMS as a source. We’ve initially implemented the JMS source
using XA transactions, but it turned out that major brokers don’t
support it or the support is buggy. For example, ActiveMQ only delivers
a handful of messages to consumers and then stops
(<a href="https://issues.apache.org/jira/projects/AMQ/issues/AMQ-7369">issue</a>).
Artemis sometimes loses messages
(<a href="https://issues.apache.org/jira/projects/ARTEMIS/issues/ARTEMIS-2546">issue</a>).
RabbitMQ doesn't support two-phase transactions at all.</p>
<p>Therefore for JMS source we implemented a different strategy. We
acknowledge consumption in the 2nd phase of the snapshot. But if the job
fails after the snapshot is successful but before we manage to
acknowledge, already processed messages could be redelivered, so we
store the IDs of seen messages in the snapshot and then use that to
deduplicate. If you’re interested in details, check the <a href="https://github.com/hazelcast/hazelcast-jet/blob/master/hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/connector/StreamJmsP.java">source
code</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="real-life-issues"></a><a href="#real-life-issues" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Real-life issues</h2>
<p>As mentioned above, some brokers have incorrect or buggy XA
implementation. In other cases, prepared transactions are rolled back
when the client disconnects (for example in
<a href="https://jira.mariadb.org/browse/MDEV-742">MariaDB</a> or <a href="https://github.com/h2database/h2database/issues/2347">H2
Database</a>) - these
systems are not usable at all. On the contrary, other implementations
keep even non-prepared transactions, such as Artemis
(<a href="https://issues.apache.org/jira/browse/ARTEMIS-2559">issue</a>, fixed
recently). Artemis doesn't even return these transactions when calling
<code>recover()</code>, the XA API method to list prepared transactions, but those
transactions still exist and hold locks. Transaction interleaving is
mostly also not supported, this prevents us from doing any work while
waiting for the 2nd phase.</p>
<p>Apache Kafka, while having all the building blocks needed to implement
XA standard, has its own API. It also lacks a method to commit a
transaction after reconnection, but we’ve been able to do it by calling
a few <a href="https://github.com/hazelcast/hazelcast-jet/blob/master/extensions/kafka/src/main/java/com/hazelcast/jet/kafka/impl/ResumeTransactionUtil.java#L43-L64">private
methods</a>.
Also it binds transaction ID to the connection which forces us to have
multiple open connections.</p>
<h2><a class="anchor" aria-hidden="true" id="transaction-id-pool"></a><a href="#transaction-id-pool" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Transaction ID pool</h2>
<p>Due to the above real-life limitations in most connectors we use two
transaction IDs interchangeably per processor. This avoids the need for
the <code>recover()</code> method to list prepared transactions, which is
unreliable or missing. Instead, we just probe known transaction IDs for
existence.</p>
<p>This tactic also avoids the problem with Apache Kafka that it binds the
transaction ID to a connection: we keep a pool of 2 connections in each
processor instead and we don't have to open a new connection after each
snapshot.</p>
<p>All connectors except for the file sink use this approach, including the
JMS and JDBC sinks
<a href="https://github.com/hazelcast/hazelcast-jet/pull/1813">planned</a> for 4.1.</p>
<h2><a class="anchor" aria-hidden="true" id="conclusion"></a><a href="#conclusion" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Conclusion</h2>
<p>The new feature allowed us to implement exactly-once guarantee for
sources and sinks where it previously wasn't possible. Even though these
kinds of connectors are not ideal for a distributed system because they
generally are not distributed, they still are very useful for
integration with existing systems. JMS source, Kafka sink and file sink
are available out-of-the-box in Jet 4.0.</p>
<p>If you consider writing your own exactly-once connector, currently you
have to implement the Core API <code>Processor</code> class. We consider
introducing some higher-level API in the future.</p>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/01/28/new-website">Announcing New Documentation Website</a></h1><p class="post-meta">January 28, 2020</p><div class="authorBlock"><p class="post-authorName"><a href="http://twitter.com/emndmrc" target="_blank" rel="noreferrer noopener">Emin Demirci</a></p><div class="authorPhoto"><a href="http://twitter.com/emndmrc" target="_blank" rel="noreferrer noopener"><img src="https://3l0wd94f0qdd10om8642z9se-wpengine.netdna-ssl.com/wp-content/uploads/2019/07/emin-demirci-170x170.png" alt="Emin Demirci"/></a></div></div></header><article class="post-content"><div><span><p>We are excited to tell you that we've just launched a new website for
Hazelcast Jet, where we share technical content regarding the project
including how-to-guides and technical design documents.</p>
<p>We'll keep this website frequently updated. Stay tuned!</p>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2019/11/12/stream-deduplication">Stream Deduplication with Hazelcast Jet</a></h1><p class="post-meta">November 12, 2019</p><div class="authorBlock"><p class="post-authorName"><a href="https://twitter.com/jerrinot" target="_blank" rel="noreferrer noopener">Jaromir Hamala</a></p><div class="authorPhoto"><a href="https://twitter.com/jerrinot" target="_blank" rel="noreferrer noopener"><img src="https://3l0wd94f0qdd10om8642z9se-wpengine.netdna-ssl.com/wp-content/uploads/2019/02/jaromir-hamala-170x170.png" alt="Jaromir Hamala"/></a></div></div></header><article class="post-content"><div><span><p>Hazelcast Jet 3.2 introduces stateful map, filter, and flatmap
operations, which are very strong primitives. In this blog, I am going
to show you how to use stateful filter for detecting and removing
duplicate elements in a stream.</p>
<h2><a class="anchor" aria-hidden="true" id="why-deduplication"></a><a href="#why-deduplication" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Why Deduplication?</h2>
<p>Deduplication is often used to achieve idempotency or effectively-once
delivery semantics in messaging systems. Imagine you have a
microservices architecture where individual microservices use a message
broker to communicate with each other. Achieving exactly-once semantics
is a hard problem.</p>
<p>If you cannot have exactly-once then you are typically left with
at-most-once and at-least-once semantics. At-most-once means messages
can get lost. This is often unacceptable. At-least-once means messages
cannot get lost, but some can be delivered more than once. This is
oftentimes better than losing messages, yet for some use cases, it’s
still not good enough. The common solution to this problem is
effectively-once. It’s essentially at-least-once combined with duplicate
detection and removal.</p>
<h2><a class="anchor" aria-hidden="true" id="implementation-idea"></a><a href="#implementation-idea" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Implementation Idea</h2>
<p>The deduplication process is usually straightforward. Producers attach a
unique ID to each message. Consumers track all processed message IDs and
discard messages with already observed IDs. This is often easy for batch
processing as each batch has a finite size. Thus, it’s often feasible to
store all IDs observed in a given batch.</p>
<p>However, streaming systems are different beasts. Streams are
conceptually infinite and it’s not feasible to hold all observed IDs,
let alone in memory. On the other hand, it’s often sensible to assume
duplicated messages will be close to each other. Hence we can introduce
time-to-live for each ID and remove it from memory when the time-to-live
expires.</p>
<h2><a class="anchor" aria-hidden="true" id="implementation-with-hazelcast-jet"></a><a href="#implementation-with-hazelcast-jet" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Implementation with Hazelcast Jet</h2>
<p>Let’s say I am running a discussion forum and I have a microservice that
sends a new message whenever a user posts a new comment. The message
looks like this:</p>
<pre><code class="hljs css language-java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">AddNewComment</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Serializable</span> </span>{
  <span class="hljs-keyword">private</span> UUID uuid;
  <span class="hljs-keyword">private</span> String comment;
  <span class="hljs-keyword">private</span> <span class="hljs-keyword">long</span> authorId;
}
</code></pre>
<p>The UUID field is unique for each message posted. My consumer is a
Hazelcast Jet application, and I want a processing pipeline to discard
all messages with a UUID already processed in the past. It turns out to
be really trivial:</p>
<pre><code class="hljs css language-java">stage.groupingKey(AddNewComment::getUuid)
  .filterStateful(<span class="hljs-number">10_000</span>, () -&gt; <span class="hljs-keyword">new</span> <span class="hljs-keyword">boolean</span>[<span class="hljs-number">1</span>],
    (s, i) -&gt; {
        <span class="hljs-keyword">boolean</span> res = s[<span class="hljs-number">0</span>];
        s[<span class="hljs-number">0</span>] = <span class="hljs-keyword">true</span>;
        <span class="hljs-keyword">return</span> !res;
  }
);
</code></pre>
<p>How does it work? In the first step, we group a stream of incoming
comments by UUID. In the next step, we apply a filter with an array of
Booleans used as a state object. The state object will be created for
each UUID.</p>
<p>When a UUID is observed for the first time, the element inside the array
is false, so the code will flip it to true and the filtering function
returns true. This means the object will not be discarded.</p>
<p>If at some point the stream receives another comment with the same UUID,
then the filtering function receives the state object where the Boolean
inside the array is already set to true. This means the filtering
function will return false, and the duplicated object will be discarded.</p>
<p>The first parameter in the <code>filterStateful()</code> method is time-to-live.
Event time is typically in milliseconds. This means each state object
will be retained for at least 10 seconds. We have to choose this
parameter to match the longest possible time window between two
duplicated elements.</p>
<h2><a class="anchor" aria-hidden="true" id="further-improvements"></a><a href="#further-improvements" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Further Improvements</h2>
<p>Let’s encapsulate the filtering logic into a reusable unit that can be
applied to an arbitrary pipeline. We are going to use the <code>apply()</code>
method to transform a pipeline. A utility class with this method is all
that’s needed:</p>
<pre><code class="hljs css language-java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> &lt;T&gt; FunctionEx&lt;StreamStage&lt;T&gt;, StreamStage&lt;T&gt;&gt;
deduplicationWindow(<span class="hljs-keyword">long</span> window, FunctionEx&lt;T, ?&gt; extractor) {
    <span class="hljs-keyword">return</span> stage -&gt; stage.groupingKey(extractor)
                         .filterStateful(window, () -&gt; <span class="hljs-keyword">new</span> <span class="hljs-keyword">boolean</span>[<span class="hljs-number">1</span>], (s, i) -&gt; {
                             <span class="hljs-keyword">boolean</span> res = s[<span class="hljs-number">0</span>];
                             s[<span class="hljs-number">0</span>] = <span class="hljs-keyword">true</span>;
                             <span class="hljs-keyword">return</span> !res;
                         });
}
</code></pre>
<p>Whenever you need to add deduplication into a pipeline, you can simply call:</p>
<pre><code class="hljs css language-java">pipelineStage.apply(
    StreamUtils.deduplicationWindow(WINDOW_LENGTH, ID_EXTRACTOR_FUNCTION)
)
[...]
</code></pre>
<p>This makes the deduplication logic independent from your business logic
and you can reuse the same deduplication utility across all your
pipelines.</p>
<h2><a class="anchor" aria-hidden="true" id="summary"></a><a href="#summary" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Summary</h2>
<p>I have demonstrated the power of stateful stream processing and the
simplicity of the Jet API. It only takes a few lines of code to
implement custom stream deduplication. Visit the Hazelcast Jet page for
more info, or stop by our Gitter chat and let us know what you think!</p>
</span></div></article></div><div class="docs-prevnext"></div></div></div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/" class="nav-home"><img src="/img/logo-light.svg" alt="Hazelcast Jet" width="200" height="40"/></a><div><h5>Docs</h5><a href="/docs/get-started/intro">Get Started</a><a href="/docs/tutorials/kafka">Tutorials</a><a href="/docs/operations/configuration">Operations Guide</a><a href="/docs/concepts/distributed-computing">Concepts and Architecture</a></div><div><h5>Community</h5><a href="https://groups.google.com/forum/#!forum/hazelcast-jet" target="_blank" rel="noreferrer noopener">Google Groups</a><a href="http://stackoverflow.com/questions/tagged/hazelcast-jet" target="_blank" rel="noreferrer noopener">Stack Overflow</a><a href="https://gitter.im/hazelcast/hazelcast-jet">Gitter Chat</a></div><div><h5>Latest From the Blog</h5><a href="/blog/2020/02/20/transactional-processors">Transactional connectors in Hazelcast Jet</a><a href="/blog/2020/01/28/new-website">Announcing New Documentation Website</a><a href="/blog/2019/11/12/stream-deduplication">Stream Deduplication with Hazelcast Jet</a></div><div><h5>More</h5><a href="https://github.com/hazelcast/hazelcast-jet">GitHub Project</a><a href="https://github.com/hazelcast/hazelcast-jet/issues">Issue Tracker</a><a href="http://hazelcast.com/company/careers/">Work at Hazelcast</a><a class="github-button" href="https://github.com/hazelcast/hazelcast-jet" data-icon="octicon-star" data-count-href="/facebook/docusaurus/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star this project on GitHub">Star</a></div></section><section class="copyright">Copyright © 2020 Hazelcast Inc.</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '79d1e4941621b9fd761d279d4d19ed69',
                indexName: 'hazelcast-jet',
                inputSelector: '#search_input_react',
                algoliaOptions: {}
              });
            </script></body></html>